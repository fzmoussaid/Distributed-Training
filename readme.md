# Distributed computing using Ray tune

Running several trials with different set of hyperparameters.
The multiple trials are run in parallel using different resources.

## Result of the training:

![alt text](hyperparameter_tuning_result.PNG)
